{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d75ff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "\n",
    "# modeling methods\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "347d67bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that will acquire the data and prepare it for Exploratory Data Analysis\n",
    "def acquire_and_prep():\n",
    "    games = pd.read_csv('vgsales.csv')\n",
    "    # Drop missing values.\n",
    "    games.dropna(inplace=True)\n",
    "    # Convert 'Year' column into integer datatype.\n",
    "    games.Year = games.Year.astype(int)\n",
    "    # Lowercase all columns.\n",
    "    columns = [col.lower() for col in games.columns]\n",
    "    games.columns = columns\n",
    "    # Drop all observations where global sales are less than one million.\n",
    "    games = games[games.global_sales > 1.0]\n",
    "    # Create a column that gives the age of the game as opposed to the year it was released.\n",
    "    games['age'] = 2022 - games.year\n",
    "    # Create a column that combines all sales outside of North America\n",
    "    games['combined_sales'] = games.eu_sales + games.jp_sales + games.other_sales\n",
    "    # Create age_bins for the games.\n",
    "    games['age_bins'] = pd.cut(games.year, bins = [0, 2002, 2009, 2022], labels = ['old_af','middle_aged','noob'])\n",
    "    # Create two separate dataframes. One for quantitative values and the other for qualitative values.\n",
    "    quantitative_values = games.select_dtypes(exclude=['object','category']).columns\n",
    "    qualitative_values = games.select_dtypes(include=['object', 'category']).columns\n",
    "    \n",
    "    \n",
    "    return games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "058c1e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data():\n",
    "    # split test off, 20% of original df size. \n",
    "    train_validate, test = train_test_split(games, test_size=.2, \n",
    "                                            random_state=123)\n",
    "    \n",
    "    # split validate off, 30% of what remains (24% of original df size)\n",
    "    # thus train will be 56% of original df size. \n",
    "    train, validate = train_test_split(train_validate, test_size=.3, \n",
    "                                       random_state=123)\n",
    "    \n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b37d7d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that iterates through the categorical columns and plots a Seaborn barplot.\n",
    "def qualitative_boxplot():\n",
    "    plt.figure(figsize=(36,56))\n",
    "    for i, col in enumerate(qualitative_values[1:]):\n",
    "        plot_number = i + 1\n",
    "        plt.subplot(4,1,plot_number)\n",
    "        plt.title(col)\n",
    "        sns.barplot(x=col, y=\"na_sales\", data=train)\n",
    "        na_sales_rate = train.na_sales.mean()\n",
    "        plt.axhline(na_sales_rate, label=\"North American Sales Rate\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(False)\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db626a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that iterates through the categorical features and runs the proper statistical test.\n",
    "def qualitative_stats_test():\n",
    "    for pub in leading_publishers:\n",
    "        publisher_mean = train[train.publisher == pub].na_sales\n",
    "        overall_mean = train.na_sales.mean()\n",
    "    \n",
    "        t, p = stats.ttest_1samp(publisher_mean, overall_mean)\n",
    "    \n",
    "        print(t, p/2)\n",
    "        \n",
    "        if p/2 > alpha:\n",
    "            print(\"We fail to reject the null hypotheis.\")\n",
    "        elif t < 0:\n",
    "            print(\"We fail to reject null hypothesis.\")\n",
    "        else:\n",
    "            print(f\"We reject the null hypothesis. There is sufficient evidence to move forward with the understanding that {pub}'s average sales are greater than the population average.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44e14ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_publishers():\n",
    "    contenders = []\n",
    "    for pubs in train.publisher.unique():    \n",
    "        if (train.publisher == pubs).sum() > 10:\n",
    "            contenders.append(pubs)\n",
    "    top_pubs = []\n",
    "    for publisher in contenders:\n",
    "        if train[train['publisher'] == publisher].na_sales.mean() > train.na_sales.mean():\n",
    "            top_pubs.append(publisher)\n",
    "    return top_pubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f67d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
